{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e6d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b265ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kumar\\Desktop\\anaco\\envs\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x000001F2076CAAD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F2076CA9E0>, model_name='llama-3.1-8b-instant', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"llama-3.1-8b-instant\",groq_api_key=groq_api_key,temperature=0)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07c5b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,AIMessage,SystemMessage,trim_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39bf0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e4e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4809d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c95edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My name is kumar, i am 21 years old and I am into genai, mlops, data science\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd73ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Kumar! You're 21 years old and already interested in GenAI, MLOps, and Data Science. That's impressive!\\n\\nAt 21, you're in a great position to explore these fields and build a strong foundation for your future career. Here are some suggestions to help you make the most of your interests:\\n\\n**Learning:**\\n\\n1. **Take online courses**: Websites like Coursera, edX, and Udemy offer courses on GenAI, MLOps, and Data Science. You can also check out platforms like DataCamp and Kaggle.\\n2. **Read books and research papers**: Stay up-to-date with the latest developments in these fields by reading books and research papers.\\n3. **Join online communities**: Participate in online forums like Kaggle, Reddit (r/MachineLearning and r/DataScience), and GitHub to connect with other professionals and learn from their experiences.\\n\\n**Projects:**\\n\\n1. **Build a conversational AI model**: Use a library like Rasa or Dialogflow to create a conversational AI model that can understand and respond to user queries.\\n2. **Deploy a machine learning model**: Use a framework like TensorFlow or PyTorch to build a machine learning model, and then deploy it using a platform like AWS SageMaker or Google Cloud AI Platform.\\n3. **Analyze a public dataset**: Choose a public dataset, such as the Iris dataset or the Titanic dataset, and perform exploratory data analysis, feature engineering, and model selection to gain insights.\\n\\n**Career:**\\n\\n1. **Consider a graduate degree**: If you're interested in pursuing a career in academia or research, a graduate degree in a relevant field may be beneficial.\\n2. **Look for internships**: Apply for internships at companies that align with your interests and skills.\\n3. **Network**: Attend industry events, conferences, and meetups to connect with other professionals and learn about new opportunities.\\n\\n**Personal Development:**\\n\\n1. **Develop your programming skills**: Focus on languages like Python, R, or Julia, and learn to work with popular libraries and frameworks.\\n2. **Improve your data visualization skills**: Learn to create effective visualizations using tools like Tableau, Power BI, or D3.js.\\n3. **Practice problem-solving**: Participate in competitions like Kaggle, HackerRank, or CodeWars to improve your problem-solving skills.\\n\\nRemember, Kumar, the key to success in these fields is to stay curious, keep learning, and adapt to new developments. Don't be afraid to ask questions, seek help, and explore new areas of interest!\\n\\nWhat do you think you'd like to focus on next, Kumar?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4067866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It seems like you're on the right track, Kumar. Based on your interests in GenAI, MLOps, and Data Science, here are some potential career paths and areas of focus:\\n\\n**Career Paths:**\\n\\n1. **Data Scientist**: You'll work with data to identify trends, create models, and communicate insights to stakeholders.\\n2. **Machine Learning Engineer**: You'll design, develop, and deploy machine learning models to solve real-world problems.\\n3. **AI/ML Researcher**: You'll explore new ideas and techniques in AI and ML, and develop innovative solutions to complex problems.\\n4. **Business Intelligence Developer**: You'll create data visualizations, reports, and dashboards to help organizations make informed decisions.\\n5. **Cloud Computing Professional**: You'll design, deploy, and manage cloud-based systems and applications.\\n\\n**Areas of Focus:**\\n\\n1. **Natural Language Processing (NLP)**: You'll work on developing AI models that can understand and generate human language.\\n2. **Computer Vision**: You'll develop AI models that can interpret and understand visual data from images and videos.\\n3. **Predictive Maintenance**: You'll use machine learning to predict when equipment or systems will fail, and develop strategies for maintenance and repair.\\n4. **Recommendation Systems**: You'll develop AI models that can suggest products, services, or content to users based on their preferences and behavior.\\n5. **Healthcare Analytics**: You'll work on developing AI models that can analyze medical data to improve patient outcomes and healthcare delivery.\\n\\n**Emerging Trends:**\\n\\n1. **Explainable AI (XAI)**: You'll develop techniques to make AI models more transparent and interpretable.\\n2. **Edge AI**: You'll work on developing AI models that can run on edge devices, such as smartphones or IoT sensors.\\n3. **Quantum AI**: You'll explore the potential of quantum computing for AI and ML applications.\\n4. **Transfer Learning**: You'll develop techniques to transfer knowledge from one domain to another, and improve the performance of AI models.\\n5. **Human-AI Collaboration**: You'll work on developing AI systems that can collaborate with humans to achieve common goals.\\n\\n**Your Strengths:**\\n\\n1. **Curiosity**: You're interested in exploring new areas of AI and ML.\\n2. **Problem-solving**: You're eager to tackle complex problems and develop innovative solutions.\\n3. **Adaptability**: You're willing to learn new skills and adapt to new technologies.\\n4. **Creativity**: You're open to exploring new ideas and approaches to AI and ML.\\n5. **Collaboration**: You're interested in working with others to achieve common goals.\\n\\nBased on these strengths, I think you'd be a great fit for roles that involve:\\n\\n1. **Research and development**: You'll work on exploring new ideas and techniques in AI and ML.\\n2. **Innovation**: You'll develop innovative solutions to complex problems.\\n3. **Collaboration**: You'll work with others to achieve common goals.\\n4. **Problem-solving**: You'll tackle complex problems and develop effective solutions.\\n5. **Adaptability**: You'll learn new skills and adapt to new technologies.\\n\\nWhat do you think, Kumar? Does this sound like a good fit for you?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 665, 'prompt_tokens': 1796, 'total_tokens': 2461, 'completion_time': 0.705617531, 'completion_tokens_details': None, 'prompt_time': 0.140187376, 'prompt_tokens_details': None, 'queue_time': 0.057401123, 'total_time': 0.845804907}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c105a-2b0c-7d61-ae94-cd4b45a48694-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1796, 'output_tokens': 665, 'total_tokens': 2461})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what am i onto\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef1dab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful assistant. Answer all the questions\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e19189fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "991aa9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nice to meet you, Kumar. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 49, 'total_tokens': 64, 'completion_time': 0.018079316, 'completion_tokens_details': None, 'prompt_time': 0.003885829, 'prompt_tokens_details': None, 'queue_time': 0.063163761, 'total_time': 0.021965145}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c107a-1dfb-78c2-9ce6-e6d23c844463-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 49, 'output_tokens': 15, 'total_tokens': 64})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"i am kumar\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fa691a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "018214ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ab1b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke([\n",
    "    HumanMessage(content=\"My name is kumar\")],\n",
    "                                     config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0925936d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Kumar. How can I assist you today?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a010124c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Kumar, the person I'm having a conversation with right now.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 77, 'total_tokens': 93, 'completion_time': 0.027529743, 'completion_tokens_details': None, 'prompt_time': 0.004427194, 'prompt_tokens_details': None, 'queue_time': 0.048912866, 'total_time': 0.031956937}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c107e-fb3d-75c2-8b28-76185c14cdef-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 77, 'output_tokens': 16, 'total_tokens': 93})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([\n",
    "    HumanMessage(content=\"who am i\")],\n",
    "                                     config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b58513c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy='last',\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfe9f181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kumar\\Desktop\\anaco\\envs\\langchain\\lib\\site-packages\\langchain_core\\language_models\\base.py:328: UserWarning: Using fallback GPT-2 tokenizer for token counting. Token counts may be inaccurate for non-GPT-2 models. For accurate counts, use a model-specific method if available.\n",
      "  return len(self.get_token_ids(text))\n",
      "c:\\Users\\kumar\\Desktop\\anaco\\envs\\langchain\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kumar\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "365c4465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You like vanilla ice cream!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "864a6f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked me the math problem 2 + 2.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ea98c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the MEssage History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02322fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'your name is Bob.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d202ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked the math problem 2 + 2.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139cfc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
